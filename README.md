# Language processing

## Description
Modeling Order in Neural Word Embeddings at Scale is an interesting work on word embeddings, which considers word orders from the well-known word2vec (a.k.a. CBOW and skip-gram, Mikolov et al., 2013). This project will implement the novel paper, which revise the word2vec into a multiple hidden layer. This new approach can include the order information into the word embeddings.

## Plan

### Todo List
- [x] Study the main algorithm and related work.
- [ ] Implement the algorithm.
- [ ] Validate the code and improve the performance.

### Time Schedule
Use securing confined his shutters. Delightful as he it acceptance an solicitude discretion reasonably. Carriage we husbands advanced an perceive greatest. Totally dearest expense on demesne ye he.

| Stage | Start  | End | Goals |
| ------------- | ------------- | ------------- | ------------- |
| 1 | 02/01/16  | 02/07/16  | Project Selection, Plan Discussion, and Proposal Draft Writing |
| 2 | 02/08/16  | 02/24/16  | System Design, Resource Discovery, Project Implementation, Document Writing  |
| 3 | 02/25/16  | 02/29/16  | User Manual Writing and Presentation Making  |

## Resource
- [BitTiger Project: AppStore - Crawler](https://slack-files.com/T0GUEMKEZ-F0J4G9QTT-274d3bc97e)
- [Original paper](http://jmlr.org/proceedings/papers/v37/trask15.pdf)

## License
See the [LICENSE](LICENSE.md) file for license rights and limitations (MIT).

## Project Information
- category: NLP
- team: G-18
- description: Modeling Order in Neural Word Embeddings at Scale.
- stack: ML, NLP
